{
    "chatgpt": {
        "model_id": "gpt-3.5-turbo",
        "prompt_token_cost": 0.002,
        "response_token_cost": 0.002,
        "temperature": 0.8,
        "top_k": 50,
        "max_tokens": 4096,
        "stop": null,
        "organization": "",
        "api_key": "API-KEY"
    },
    "chatgpt4": {
        "model_id": "gpt-4",
        "prompt_token_cost": 0.03,
        "response_token_cost": 0.06,
        "temperature": 1,
        "max_tokens": 4096,
        "stop": null,
        "organization": "",
        "api_key": "API-KEY"
    },
    "llama7b-hf": {
        "model_id": "Llama-2-7b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.8,
        "top_k": 50,
        "max_tokens": 4096,
        "loacl_model_path": ""
    },
    "llama13b-hf": {
        "model_id": "Llama-2-13b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.8,
        "top_k": 50,
        "max_tokens": 4096
    },
    "llama70b-hf": {
        "model_id": "Llama-2-70b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.8,
        "top_k": 50,
        "max_tokens": 4096
    },
    "Baichuan2-7B": {
        "model_id": "Baichuan2-7B-Chat",
        "cache_dir": "./baichuan",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.8,
        "top_k": 50,
        "loacl_model_path": "",
        "max_tokens": 4096
    }
}